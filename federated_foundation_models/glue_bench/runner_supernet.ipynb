{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments,\n",
    "    AutoTokenizer,PreTrainedTokenizerFast,\n",
    "    AutoModel,\n",
    "    BertForSequenceClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    "    )\n",
    "from trainer_supernet import SupernetTrainer\n",
    "from transformers import RobertaTokenizerFast, T5Tokenizer\n",
    "from transformers import DistilBertForSequenceClassification, RobertaForSequenceClassification, T5ForConditionalGeneration\n",
    "import numpy as np\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import logging\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "from nncf import NNCFConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Create Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to directory to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n",
    "                \"with private models).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    test_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input test data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=384,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "                \"than this will be truncated, sequences shorter will be padded.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Whether to pad all samples to `max_seq_length`. If False, will pad the samples dynamically when\"\n",
    "                \" batching to the maximum length in the batch (which can be faster on GPU but will be slower on TPU).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    version_2_with_negative: bool = field(\n",
    "        default=False, metadata={\"help\": \"If true, some of the examples do not have an answer.\"}\n",
    "    )\n",
    "    null_score_diff_threshold: float = field(\n",
    "        default=0.0,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The threshold used to select the null answer: if the best answer has a score that is less than \"\n",
    "                \"the score of the null answer minus this threshold, the null answer is selected for this example. \"\n",
    "                \"Only useful when `version_2_with_negative=True`.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    doc_stride: int = field(\n",
    "        default=128,\n",
    "        metadata={\"help\": \"When splitting up a long document into chunks, how much stride to take between chunks.\"},\n",
    "    )\n",
    "    n_best_size: int = field(\n",
    "        default=20,\n",
    "        metadata={\"help\": \"The total number of n-best predictions to generate when looking for an answer.\"},\n",
    "    )\n",
    "    max_answer_length: int = field(\n",
    "        default=30,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The maximum length of an answer that can be generated. This is needed because the start \"\n",
    "                \"and end predictions are not conditioned on one another.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if (\n",
    "            self.dataset_name is None\n",
    "            and self.train_file is None\n",
    "            and self.validation_file is None\n",
    "            and self.test_file is None\n",
    "        ):\n",
    "            raise ValueError(\"Need either a dataset name or a training/validation file/test_file.\")\n",
    "        else:\n",
    "            if self.train_file is not None:\n",
    "                extension = self.train_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n",
    "            if self.validation_file is not None:\n",
    "                extension = self.validation_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\"], \"`validation_file` should be a csv or a json file.\"\n",
    "            if self.test_file is not None:\n",
    "                extension = self.test_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\"], \"`test_file` should be a csv or a json file.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing training data\n",
    "### 1.1 Define a tikenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples, tokenizer, dataset,model=None):\n",
    "    if dataset in [\"sst2\", \"cola\"]:\n",
    "\n",
    "        return tokenizer(examples['sentence'], padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "    elif dataset == \"mnli\":\n",
    "        return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n",
    "    elif dataset == \"qqp\":\n",
    "        return tokenizer(examples[\"question1\"], examples[\"question2\"], padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n",
    "    elif dataset == \"qnli\":\n",
    "        return tokenizer(examples[\"question\"], examples[\"sentence\"], padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "    elif dataset in [\"mrpc\", \"stsb\", \"rte\"]:\n",
    "        return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/homes/yusx/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 129.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'sst2'\n",
    "    \n",
    "num_classes = {\n",
    "    \"mnli\": 3,\n",
    "    \"qqp\": 2,\n",
    "    \"qnli\": 2,\n",
    "    \"sst2\": 2,\n",
    "    \"stsb\": 1,\n",
    "    \"mrpc\": 2,\n",
    "    \"rte\": 2,\n",
    "    \"cola\": 2,\n",
    "    }\n",
    "\n",
    "dataset = load_dataset(\"glue\", dataset_name)\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model & Tokenizer\n",
    "### 2.1 Get model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-large-uncased-whole-word-masking'\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "config.num_labels = num_classes[dataset_name]\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForQuestionAnswering\n",
    "# model_qa = AutoModelForQuestionAnswering.from_pretrained(model_name, config = config)\n",
    "# print(model_qa)\n",
    "# model_qa = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Initialize pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "# kd_teacher_model = copy.deepcopy(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='bert-large-uncased-whole-word-masking', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "   model_name,\n",
    "   use_fast=True,\n",
    ")\n",
    "print(tokenizer)\n",
    "if not isinstance(tokenizer, PreTrainedTokenizerFast):\n",
    "    raise ValueError(\n",
    "        \"This example script only works for models that have a fast tokenizer. Checkout the big table of models at\"\n",
    "        \" https://huggingface.co/transformers/index.html#supported-frameworks to find the model types that meet\"\n",
    "        \" this requirement\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /homes/yusx/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a4ff0bfa4db56cf0.arrow\n",
      "Loading cached processed dataset at /homes/yusx/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-19ce2cdb4180a76a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> train_dataset size: 67349\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(lambda examples: tokenize_function(examples, tokenizer, dataset_name), batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(lambda examples: tokenize_function(examples, tokenizer, dataset_name), batched=True)\n",
    "# logging.info(\"=====> train_dataset size: {}\".format(len(tokenized_train_dataset)))\n",
    "print(\"=====> train_dataset size: {}\".format(len(tokenized_train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, task):\n",
    "    predictions, labels = eval_pred\n",
    "    if task == \"stsb\":\n",
    "        pearson_corr, _ = pearsonr(predictions.squeeze(), labels)\n",
    "        return {\"pearson_corr\": pearson_corr}\n",
    "    else:\n",
    "    \n",
    "        predictions = predictions.argmax(-1)\n",
    "        return {\"accuracy\": accuracy_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create NNCF Supernet from Base Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually setup some args to align with the arguments in BoostrapNAS demo\n",
    "class Args:\n",
    "    pass\n",
    "\n",
    "training_args = Args()\n",
    "training_args.__setattr__('kd_teacher_model',model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "kd_teacher_model = None\n",
    "if training_args.kd_teacher_model:\n",
    "    kd_teacher_model = BertForSequenceClassification.from_pretrained(\n",
    "        training_args.kd_teacher_model,\n",
    "        from_tf=bool(\".ckpt\" in training_args.kd_teacher_model),\n",
    "        # cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "    kd_teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually setup some args to align with the arguments in BoostrapNAS demo\n",
    "training_args.__setattr__('nncf_config','./nncf_config.json')\n",
    "training_args.__setattr__('do_train',True)\n",
    "training_args.__setattr__('do_eval',True)\n",
    "training_args.__setattr__('output_dir','./log_dir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually setup some args to align with the arguments in BoostrapNAS demo\n",
    "model_args = Args()\n",
    "model_args.__setattr__('model_revision','model_revision')\n",
    "model_args.__setattr__('use_auth_token',False)\n",
    "model_args.__setattr__('model_name_or_path',model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nncf_config = None\n",
    "create_importance_mask_fn = None\n",
    "if training_args.nncf_config is not None:\n",
    "    nncf_config = NNCFConfig.from_json(training_args.nncf_config)\n",
    "    if nncf_config.get(\"log_dir\") is None:\n",
    "        nncf_config[\"log_dir\"] = training_args.output_dir\n",
    "    if not os.path.exists(training_args.output_dir) and training_args.local_rank in [-1, 0]:\n",
    "        os.makedirs(nncf_config[\"log_dir\"])\n",
    "\n",
    "    # split nncf_config --> bnas + movement sparsity\n",
    "    compression_algo_names = [algo['algorithm'] for algo in nncf_config.get('compression', [])]\n",
    "    if 'movement_sparsity' in compression_algo_names:\n",
    "        sparsity_nncf_config = copy.deepcopy(nncf_config)\n",
    "        if 'bootstrapNAS' in sparsity_nncf_config:\n",
    "            del sparsity_nncf_config['bootstrapNAS']\n",
    "\n",
    "        def generate_importance_mask_weight(model_state_dict, debug_mode=False, save_folder='movement_sparsity',\n",
    "                                            resume_model='/data2/yzheng/bert_squad_result/weight_reorg/checkpoint-29509/pytorch_model.bin'):\n",
    "            # create movement sparsity ctrl\n",
    "            sparsity_ctrl, sparsity_model = BertForSequenceClassification.from_pretrained(\n",
    "                model_name,\n",
    "                from_tf=bool(\".ckpt\" in model_name),\n",
    "                config=config,\n",
    "                # cache_dir=model_args.cache_dir,\n",
    "                revision=model_args.model_revision,\n",
    "                use_auth_token=True if model_args.use_auth_token else None,\n",
    "                nncf_config=sparsity_nncf_config,\n",
    "                nncf_eval=nncf_config is not None and training_args.do_eval and not training_args.do_train,\n",
    "            )\n",
    "            sparsity_model.load_state_dict(model_state_dict, strict=False) # use current bnas model state dict\n",
    "\n",
    "            sparsity_trainer = SupernetTrainer(\n",
    "                model=sparsity_model,\n",
    "                args=training_args,\n",
    "                train_dataset=tokenized_train_dataset if training_args.do_train else None,\n",
    "                eval_dataset=tokenized_train_dataset if training_args.do_eval else None,\n",
    "                eval_examples=test_dataset if training_args.do_eval else None,\n",
    "                tokenizer=tokenizer,\n",
    "                # data_collator=data_collator,\n",
    "                # post_process_function=post_processing_function,\n",
    "                compute_metrics=lambda eval_pred: compute_metrics(eval_pred, dataset_name),\n",
    "                compression_ctrl=sparsity_ctrl,\n",
    "                kd_teacher_model=kd_teacher_model,\n",
    "                debug_mode=debug_mode,\n",
    "                resume_model=resume_model\n",
    "            )\n",
    "\n",
    "            sparsity_trainer.train()\n",
    "            sparsity_trainer.save_model(os.path.join(training_args.output_dir, save_folder))\n",
    "            return sparsity_model\n",
    "\n",
    "        create_importance_mask_fn = generate_importance_mask_weight\n",
    "\n",
    "retval = BertForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    # cache_dir=model_args.cache_dir,\n",
    "    # revision=model_args.model_revision,\n",
    "    # use_auth_token=True if model_args.use_auth_token else None,\n",
    "    nncf_config=nncf_config,\n",
    "    nncf_eval=nncf_config is not None and training_args.do_eval and not training_args.do_train,\n",
    "    )\n",
    "\n",
    "if nncf_config is None:\n",
    "    model = retval\n",
    "    compression_ctrl = None\n",
    "else:\n",
    "    # if movement sparsity is in config,\n",
    "    # then compression_ctrl = [bnas_ctrl, movement_sparsity_ctrl]\n",
    "    # model = [bnas_model, movement_sparsity_model]\n",
    "    compression_ctrl, model = retval\n",
    "    compression_ctrl.multi_elasticity_handler.width_handler.create_importance_mask_fn = create_importance_mask_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): NNCFEmbedding(\n",
      "        30522, 1024, padding_idx=0\n",
      "        (pre_ops): ModuleDict()\n",
      "        (post_ops): ModuleDict()\n",
      "      )\n",
      "      (position_embeddings): NNCFEmbedding(\n",
      "        512, 1024\n",
      "        (pre_ops): ModuleDict()\n",
      "        (post_ops): ModuleDict()\n",
      "      )\n",
      "      (token_type_embeddings): NNCFEmbedding(\n",
      "        2, 1024\n",
      "        (pre_ops): ModuleDict()\n",
      "        (post_ops): ModuleDict()\n",
      "      )\n",
      "      (LayerNorm): NNCFLayerNorm(\n",
      "        (1024,), eps=1e-12, elementwise_affine=True\n",
      "        (pre_ops): ModuleDict(\n",
      "          (0): UpdateLayerNormParams(\n",
      "            (op): ElasticInputWidthLayerNormOp()\n",
      "          )\n",
      "        )\n",
      "        (post_ops): ModuleDict()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): NNCFLinear(\n",
      "                in_features=1024, out_features=1024, bias=True\n",
      "                (pre_ops): ModuleDict(\n",
      "                  (0): UpdateWeight(\n",
      "                    (op): ElasticInputWidthLinearOp()\n",
      "                  )\n",
      "                  (1): UpdateWeightAndOptionalBias(\n",
      "                    (op): ElasticOutputWidthLinearOp()\n",
      "                  )\n",
      "                )\n",
      "                (post_ops): ModuleDict()\n",
      "              )\n",
      "              (key): NNCFLinear(\n",
      "                in_features=1024, out_features=1024, bias=True\n",
      "                (pre_ops): ModuleDict(\n",
      "                  (0): UpdateWeight(\n",
      "                    (op): ElasticInputWidthLinearOp()\n",
      "                  )\n",
      "                  (1): UpdateWeightAndOptionalBias(\n",
      "                    (op): ElasticOutputWidthLinearOp()\n",
      "                  )\n",
      "                )\n",
      "                (post_ops): ModuleDict()\n",
      "              )\n",
      "              (value): NNCFLinear(\n",
      "                in_features=1024, out_features=1024, bias=True\n",
      "                (pre_ops): ModuleDict(\n",
      "                  (0): UpdateWeight(\n",
      "                    (op): ElasticInputWidthLinearOp()\n",
      "                  )\n",
      "                  (1): UpdateWeightAndOptionalBias(\n",
      "                    (op): ElasticOutputWidthLinearOp()\n",
      "                  )\n",
      "                )\n",
      "                (post_ops): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): NNCFLinear(\n",
      "                in_features=1024, out_features=1024, bias=True\n",
      "                (pre_ops): ModuleDict(\n",
      "                  (0): UpdateWeight(\n",
      "                    (op): ElasticInputWidthLinearOp()\n",
      "                  )\n",
      "                )\n",
      "                (post_ops): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): NNCFLayerNorm(\n",
      "                (1024,), eps=1e-12, elementwise_affine=True\n",
      "                (pre_ops): ModuleDict(\n",
      "                  (0): UpdateLayerNormParams(\n",
      "                    (op): ElasticInputWidthLayerNormOp()\n",
      "                  )\n",
      "                )\n",
      "                (post_ops): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): NNCFLinear(\n",
      "              in_features=1024, out_features=4096, bias=True\n",
      "              (pre_ops): ModuleDict(\n",
      "                (0): UpdateWeight(\n",
      "                  (op): ElasticInputWidthLinearOp()\n",
      "                )\n",
      "                (1): UpdateWeightAndOptionalBias(\n",
      "                  (op): ElasticOutputWidthLinearOp()\n",
      "                )\n",
      "              )\n",
      "              (post_ops): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): NNCFLinear(\n",
      "              in_features=4096, out_features=1024, bias=True\n",
      "              (pre_ops): ModuleDict(\n",
      "                (0): UpdateWeight(\n",
      "                  (op): ElasticInputWidthLinearOp()\n",
      "                )\n",
      "              )\n",
      "              (post_ops): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): NNCFLayerNorm(\n",
      "              (1024,), eps=1e-12, elementwise_affine=True\n",
      "              (pre_ops): ModuleDict(\n",
      "                (0): UpdateLayerNormParams(\n",
      "                  (op): ElasticInputWidthLayerNormOp()\n",
      "                )\n",
      "              )\n",
      "              (post_ops): ModuleDict()\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): NNCFLinear(\n",
      "        in_features=1024, out_features=1024, bias=True\n",
      "        (pre_ops): ModuleDict(\n",
      "          (0): UpdateWeight(\n",
      "            (op): ElasticInputWidthLinearOp()\n",
      "          )\n",
      "        )\n",
      "        (post_ops): ModuleDict()\n",
      "      )\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): NNCFLinear(\n",
      "    in_features=1024, out_features=2, bias=True\n",
      "    (pre_ops): ModuleDict(\n",
      "      (0): UpdateWeight(\n",
      "        (op): ElasticInputWidthLinearOp()\n",
      "      )\n",
      "    )\n",
      "    (post_ops): ModuleDict()\n",
      "  )\n",
      "  (_nncf): NNCFNetworkInterface()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.__setattr__('full_determinism',False)\n",
    "training_args.__setattr__('seed',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'skip_memory_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[39m=\u001b[39m SupernetTrainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m      4\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtokenized_train_dataset \u001b[39mif\u001b[39;49;00m training_args\u001b[39m.\u001b[39;49mdo_train \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mtokenized_test_dataset \u001b[39mif\u001b[39;49;00m training_args\u001b[39m.\u001b[39;49mdo_eval \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      6\u001b[0m     eval_examples\u001b[39m=\u001b[39;49mtest_dataset \u001b[39mif\u001b[39;49;00m training_args\u001b[39m.\u001b[39;49mdo_eval \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      7\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m      8\u001b[0m     \u001b[39m# data_collator=data_collator,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# post_process_function=post_processing_function,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m eval_pred: compute_metrics(eval_pred, dataset_name),\n\u001b[1;32m     11\u001b[0m     compression_ctrl\u001b[39m=\u001b[39;49mcompression_ctrl,\n\u001b[1;32m     12\u001b[0m     kd_teacher_model\u001b[39m=\u001b[39;49mkd_teacher_model\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/sixing/nncf_bootstrapnas/federated_foundation_models/glue_bench/trainer_supernet.py:44\u001b[0m, in \u001b[0;36mSupernetTrainer.__init__\u001b[0;34m(self, eval_examples, post_process_function, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, eval_examples\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, post_process_function\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 44\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_examples \u001b[39m=\u001b[39m eval_examples\n\u001b[1;32m     46\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_process_function \u001b[39m=\u001b[39m post_process_function\n",
      "File \u001b[0;32m~/sixing/transformers/src/transformers/trainer.py:358\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, compression_ctrl, kd_teacher_model, debug_mode, resume_model)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_model \u001b[39m=\u001b[39m resume_model\n\u001b[1;32m    357\u001b[0m \u001b[39m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_memory_tracker \u001b[39m=\u001b[39m TrainerMemoryTracker(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mskip_memory_metrics)\n\u001b[1;32m    359\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_memory_tracker\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    361\u001b[0m \u001b[39m# set the correct log level depending on the node\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Args' object has no attribute 'skip_memory_metrics'"
     ]
    }
   ],
   "source": [
    "trainer = SupernetTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=tokenized_test_dataset if training_args.do_eval else None,\n",
    "    eval_examples=test_dataset if training_args.do_eval else None,\n",
    "    tokenizer=tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    # post_process_function=post_processing_function,\n",
    "    compute_metrics=lambda eval_pred: compute_metrics(eval_pred, dataset_name),\n",
    "    compression_ctrl=compression_ctrl,\n",
    "    kd_teacher_model=kd_teacher_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    if nncf_config is not None:\n",
    "        train_result, model, elasticity_ctrl = train_result\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    if nncf_config is not None and training_args.do_search:\n",
    "        resuming_checkpoint_path = None\n",
    "        if resuming_checkpoint_path is None:\n",
    "            search_algo = SearchAlgorithm.from_config(model, elasticity_ctrl, nncf_config)\n",
    "        else:\n",
    "            search_algo = SearchAlgorithm.from_checkpoint(model, elasticity_ctrl, None, resuming_checkpoint_path)\n",
    "\n",
    "        def validate_model_func(model_, dataset_):\n",
    "            #trainer.model will be used to evaluate(trainer.model = model)\n",
    "            metrics = trainer.evaluate(eval_dataset=dataset_)\n",
    "            return metrics['eval_f1']\n",
    "\n",
    "        elasticity_ctrl, best_config, performance_metrics = search_algo.run(validate_model_func,\n",
    "                                                                            eval_dataset,\n",
    "                                                                            training_args.output_dir)\n",
    "        logger.info(\"Best config: {best_config}\".format(best_config=best_config))\n",
    "        logger.info(\"Performance metrics: {performance_metrics}\".format(performance_metrics=performance_metrics))\n",
    "\n",
    "        search_algo.visualize_search_progression()\n",
    "        search_algo.search_progression_to_csv()\n",
    "        search_algo.evaluators_to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nncf_huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
